{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "\n",
    "from flask import Flask, request\n",
    "app = Flask(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:test\n"
     ]
    }
   ],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.info(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data.csv\"\n",
    "latest_pkl = \"latest.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load/Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl(file):\n",
    "    df01 = pd.read_csv(file)\n",
    "    df01['Transaction Date'] = pd.to_datetime(df01['Transaction Date'], infer_datetime_format=True)\n",
    "    df01.rename(columns={'Transaction Date':'Transaction_Date'}, inplace=True)\n",
    "\n",
    "    data = df01.drop(['Transaction_Date'], axis=1)\n",
    "    data.index = df01.Transaction_Date\n",
    "\n",
    "    data01 = data[(data[\"ATM Name\"]==1)]\n",
    "    data01 = data01.sort_index()\n",
    "\n",
    "    train = data01.astype(np.float64)\n",
    "    logging.info(\"ETL completed.\")\n",
    "    return train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VARMAX_Train_Model(train):\n",
    "    exog = train[['Weekday','Festival Religion','Working Day','Holiday Sequence']]\n",
    "    model= sm.tsa.VARMAX(train[['Total amount Withdrawn','Amount withdrawn XYZ Card']], order=(5,0), trend='c', exog=exog)\n",
    "    model_result = model.fit(maxiter=1000, disp=False)\n",
    "    logging.info(\"Model training completed.\")\n",
    "    return model_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportModel(model_result):\n",
    "    import pickle \n",
    "    from datetime import datetime\n",
    "    \n",
    "    #latest time now\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(\"%m-%d-%Y-%H-%M-%S\")\n",
    "    \n",
    "    filename = 'ATM_VARMAX01_' + timestamp + '.pkl'\n",
    "    pickle.dump(model_result, open(filename, 'wb'))\n",
    "    logging.info(\"Model exported.\")\n",
    "    \n",
    "    return filename;\n",
    "\n",
    "def handleNewVersion(latestFileName):\n",
    "    try:\n",
    "        os.remove('latest.pkl')\n",
    "    except:\n",
    "        logging.info(\"Existing latest.pkl not found. Proceeding...\")\n",
    "    \n",
    "    newPath = shutil.copy(latestFileName, 'latest.pkl')\n",
    "    logging.info(\"Latest pkl file updated.\")\n",
    "    return 0;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(Weekday,FestivalReligion,WorkingDay,HolidaySequence):\n",
    "    # Use the loaded pickled model to make predictions \n",
    "    pkl_file = open(latest_pkl, 'rb')\n",
    "    model_result = pickle.load(pkl_file) \n",
    "    params = []\n",
    "#     test01 = test[['Weekday','Festival Religion','Working Day','Holiday Sequence']]\n",
    "#     test01 = [[5.0,4.0,0.0,1.0]]\n",
    "    test01 = [[Weekday,FestivalReligion,WorkingDay,HolidaySequence]]\n",
    "    \n",
    "    exog = test01\n",
    "    pred = model_result.get_forecast(steps=1,exog=exog)\n",
    "    pred_m = pred.predicted_mean\n",
    "    logging.info(\"Prediction task completed.\")\n",
    "    return pred_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendNewData(newData):\n",
    "    f= open(file,\"a+\")\n",
    "    if(checkNewLine()):\n",
    "        f.write(newData + '\\n')\n",
    "    else:\n",
    "        f.write('\\n' + newData + '\\n')\n",
    "    f.close()\n",
    "    logging.info(\"Appended new row -> \\n\" + newData)\n",
    "    return 0;\n",
    "\n",
    "def checkNewLine():\n",
    "    outcome = False\n",
    "    with open(file, 'rb+') as f:\n",
    "        f.seek(-1,2)\n",
    "        lastByte = f.read().decode(\"utf-8\")\n",
    "    if(lastByte == '\\n'):\n",
    "        outcome = True\n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:ETL completed.\n",
      "C:\\Users\\Kavish\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:225: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  ' ignored when e.g. forecasting.', ValueWarning)\n",
      "INFO:root:Model training completed.\n",
      "INFO:root:Model exported.\n",
      "INFO:root:Existing latest.pkl not found. Proceeding...\n",
      "INFO:root:Latest pkl file updated.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data = etl(file)\n",
    "model_output = VARMAX_Train_Model(processed_data)\n",
    "latestFileName = exportModel(model_output)\n",
    "handleNewVersion(latestFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast(5.0,4.0,0.0,1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flask Routes and Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure Flask routes\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "  return 'Flask service is up and running!'\n",
    "\n",
    "@app.route('/add')\n",
    "def add():\n",
    "    data = request.args['data']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-9-de22954274db>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-de22954274db>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    if(len(args)) == 4:\u001b[0m\n\u001b[1;37m                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def validateNewData(data):\n",
    "    valid = False\n",
    "    args = data.split(',')\n",
    "    if(len(args)) == 4:\n",
    "        valid = True\n",
    "    return valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "validateNewData(\"yay\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
